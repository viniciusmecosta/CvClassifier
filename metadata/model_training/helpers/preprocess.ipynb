{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import logging\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping = {\n",
    "    'ACCOUNTANT': 0,\n",
    "    'ADVOCATE': 1,\n",
    "    'AGRICULTURE': 2,\n",
    "    'APPAREL': 3,\n",
    "    'ARTS': 4,\n",
    "    'AUTOMOBILE': 5,\n",
    "    'AVIATION': 6,\n",
    "    'BANKING': 7,\n",
    "    'BPO': 8,\n",
    "    'BUSINESS-DEVELOPMENT': 9,\n",
    "    'CHEF': 10,\n",
    "    'CONSTRUCTION': 11,\n",
    "    'CONSULTANT': 12,\n",
    "    'DESIGNER': 13,\n",
    "    'DIGITAL-MEDIA': 14,\n",
    "    'ENGINEERING': 15,\n",
    "    'FINANCE': 16,\n",
    "    'FITNESS': 17,\n",
    "    'HEALTHCARE': 18,\n",
    "    'HR': 19,\n",
    "    'INFORMATION-TECHNOLOGY': 20,\n",
    "    'PUBLIC-RELATIONS': 21,\n",
    "    'SALES': 22,\n",
    "    'TEACHER': 23,\n",
    "    'ARCHITECT' :24,\n",
    "    'MANAGMENT' : 25\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senior_mapping = {\n",
    "    'Junior': 0,\n",
    "    'Mid-level': 1,\n",
    "    'Senior': 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords_and_lemmatize(text):\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    cleaned_text = ' '.join(text.strip().split())\n",
    "    doc = nlp(cleaned_text.lower())\n",
    "    tokens_lemmatized = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n",
    "    return ' '.join(tokens_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_classes(input_csv, class_mapping):\n",
    "    df = pd.read_csv(input_csv, encoding='utf-8',delimiter=\";\")\n",
    "    df['class_number'] = df['class'].map(class_mapping)  \n",
    "    df = df.dropna(subset=['class_number']) \n",
    "    df['class_number'] = df['class_number'].astype(int)  \n",
    "    df.to_csv(input_csv, index=False)\n",
    "    logging.info(f'CSV file with mapped classes saved in {input_csv}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def senior_classes(input_csv, senior_mapping):\n",
    "    df = pd.read_csv(input_csv,encoding='utf-8',delimiter=\";\")\n",
    "    df['senior'] = df['senior'].map(senior_mapping)\n",
    "    df['senior'] = pd.to_numeric(df['senior'], errors='coerce')\n",
    "    df['senior'].fillna(3, inplace=True) \n",
    "    df['senior'] = df['senior'].astype(int)\n",
    "    df.to_csv(input_csv, index=False)\n",
    "    logging.info(f'CSV file with mapped classes saved in {input_csv}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_csv(input_csv):\n",
    "    df = pd.read_csv(input_csv, encoding='utf-8',delimiter=\";\")\n",
    "    df = df[df['text'].apply(lambda x: x.strip() != '')]\n",
    "    df['text'] = df['text'].apply(remove_stopwords_and_lemmatize)\n",
    "    df.to_csv(input_csv, index=False, encoding='utf-8')\n",
    "    logging.info(f'Processed CSV file saved in{input_csv}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_senior_column(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df['senior'] = df['senior'].map({1: 0, 2: 1, 3: 2})\n",
    "    df.dropna(subset=['senior'], inplace=True)\n",
    "    df['senior'] = df['senior'].astype(int)\n",
    "    df.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_csv = '../csv/dataset.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_csv(input_csv):\n",
    "    df = pd.read_csv(input_csv, encoding='utf-8')\n",
    "    df = df[df['text'].apply(lambda x: x.strip() != '')]\n",
    "    df['text'] = df['text'].apply(remove_stopwords_and_lemmatize)\n",
    "    df.to_csv(input_csv, index=False, encoding='utf-8')\n",
    "    logging.info(f'Processed CSV file saved in{input_csv}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_csv = '../csv/output.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_csv(input_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senioridade_counts = df['senior'].value_counts()\n",
    "print(senioridade_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(input_csv, encoding='utf-8',delimiter=\",\")\n",
    "senioridade_counts = df['senior'].value_counts()\n",
    "print(senioridade_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df = pd.DataFrame()\n",
    "senior_values = [0, 1, 2]\n",
    "sample_size = 426\n",
    "for value in senior_values:\n",
    "    samples = df[df['senior'] == value].sample(n=sample_size, replace=True)\n",
    "    sampled_df = pd.concat([sampled_df, samples], ignore_index=True)\n",
    "sampled_df.to_csv('sampled_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
